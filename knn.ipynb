{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import os\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "# MNIST Data Loader Class\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set file paths based on added MNIST Datasets\n",
    "input_path = join(os.getcwd(), 'datasets')\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte.gz')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte.gz')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte.gz')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "#\n",
    "# Helper function to show a list of images with their relating titles\n",
    "#\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1\n",
    "\n",
    "#\n",
    "# Load MINST dataset\n",
    "#\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "#\n",
    "# Show some random training and test images \n",
    "#\n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(x_train[r])\n",
    "    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_train[r]))    \n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test[r])        \n",
    "    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n",
    "\n",
    "#show_images(images_2_show, titles_2_show)\n",
    "\n",
    "x_train = np.array(x_train).reshape((len(x_train), -1))\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test).reshape((len(x_test), -1))\n",
    "y_test = np.array(y_test)\n",
    "print(\"Training Set Data  Shape: \", x_train.shape)\n",
    "print(\"Training Set Label Shape: \", y_train.shape)\n",
    "print(\"Test Set Data  Shape: \", x_test.shape)\n",
    "print(\"Test Set Label Shape: \", y_test.shape)\n",
    "\n",
    "random_prototyping_accuracy = []\n",
    "cnn_accuracy = []\n",
    "sample_sizes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn(x_train, y_train, x_test, y_test, k):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(x_train, y_train)\n",
    "\n",
    "    y_test_pred = knn_model.predict(x_test)\n",
    "    test_acc = metrics.accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    #print(\"KNN Test Accuracy: \", test_acc*100, \"%\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_idx(sample_size, data_size):\n",
    "    rand_idx = np.array(sample_size, dtype=int)\n",
    "    rand_idx = np.int_(np.round(np.random.rand(sample_size) * (data_size-1)))\n",
    "    return rand_idx\n",
    "\n",
    "def plot_accuracies(sample_size, random_accuracy, custom_accuracy):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    #y = np.sum(random_accuracy, axis=1)/random_accuracy.shape[1]\n",
    "    #yerr = np.std(random_accuracy, axis=1)\n",
    "    #plt.figure()\n",
    "    #plt.errorbar(sample_size, y, yerr)\n",
    "\n",
    "    X_axis = np.arange(len(sample_size))\n",
    "    plt.bar(X_axis-0.2, random_accuracy, 0.4, label='random')\n",
    "    plt.bar(X_axis+0.2, cnn_accuracy, 0.4, label='cnn')\n",
    "    plt.xticks(X_axis, sample_size)\n",
    "    plt.xlabel(\"Sample size\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_random(sample_size):\n",
    "    rand_idx = get_random_idx(sample_size, x_train.shape[0])\n",
    "    rand_data = np.take(x_train, rand_idx, axis=0)\n",
    "    rand_labels = np.take(y_train, rand_idx, axis=0)\n",
    "    \n",
    "    random_prototyping_accuracy.append(run_knn(rand_data, rand_labels, x_test, y_test, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_cnn_subset():\n",
    "    subset_idxs = []\n",
    "    for i in range(10): #mnist label classes\n",
    "        for j in range(100):\n",
    "            if(y_train[j] == i):\n",
    "                subset_idxs.append(j)\n",
    "                found = 1\n",
    "                break\n",
    "        if(found == 0):\n",
    "            print(\"Couldn't find a label in 100 attempts\")\n",
    "    return subset_idxs\n",
    "\n",
    "def condense(subset_idxs, x_train, y_train, x_test, y_test):\n",
    "    subset_idxs = np.array(subset_idxs)\n",
    "    iter = 0\n",
    "    train_acc = 0\n",
    "    test_acc = 0\n",
    "    while(train_acc < 1.):\n",
    "        for i in range(x_train.shape[0]):\n",
    "            if(i in subset_idxs):\n",
    "                pass\n",
    "            else:\n",
    "                found = run_knn(np.take(x_train, subset_idxs, axis=0), np.take(y_train, subset_idxs, axis=0), np.reshape(x_train[i], (1,-1)), np.reshape(y_train[i], (1,-1)), 1)\n",
    "                if(found < 0.5):\n",
    "                    subset_idxs = np.append(subset_idxs, i)\n",
    "                    #print(\"TR idx: \", i, \", Subset size: \", subset_idxs.shape[0])\n",
    "        train_acc = run_knn(np.take(x_train, subset_idxs, axis=0), np.take(y_train, subset_idxs, axis=0), x_train, y_train, 1)\n",
    "        test_acc = run_knn(np.take(x_train, subset_idxs, axis=0), np.take(y_train, subset_idxs, axis=0), x_test, y_test, 1)\n",
    "        print(\"[Iter \", iter, \"] Subset size: \", subset_idxs.shape[0], \" Training accuracy: \", train_acc, \" Test Accuracy: \", test_acc)\n",
    "        sample_sizes.append(subset_idxs.shape[0])\n",
    "        cnn_accuracy.append(test_acc)\n",
    "        compare_random(subset_idxs.shape[0])\n",
    "        iter += 1\n",
    "    \n",
    "    with open('cnn_subset_idxs.txt', 'w') as f:\n",
    "        for subset_idx in subset_idxs:\n",
    "            f.write(\"%s\\n\" % subset_idx)\n",
    "        \n",
    "    return subset_idxs\n",
    "\n",
    "def modified_condense(x_train, y_train, x_test, y_test):\n",
    "    #subset_idxs = np.array()\n",
    "    #remaining_idxs = np.arange(0, x_train.shape[0], 1, dtype=int)\n",
    "    subset_data = []\n",
    "    subset_labels = []\n",
    "\n",
    "    for i in range(10): #mnist label classes\n",
    "        for j in range(100):\n",
    "            if(y_train[j] == i):\n",
    "                subset_data.append(x_train[j])\n",
    "                subset_labels.append(i) #y_train[j]\n",
    "                found = 1\n",
    "                break\n",
    "        if(found == 0):\n",
    "            print(\"Couldn't find a label in 100 attempts\")\n",
    "\n",
    "    subset_data = np.array(subset_data)\n",
    "    subset_labels = np.array(subset_labels)\n",
    "    print(\"Initial Subset size: \", subset_data.shape, \" \", subset_labels.shape)\n",
    "    train_acc = 0\n",
    "    iter = 0\n",
    "    prev_misclassified_idxs = []\n",
    "    misclassified_idxs = []\n",
    "    while(train_acc < 0.94):\n",
    "        if(len(misclassified_idxs) > 0.99*x_train.shape[0]):\n",
    "            misclassified_idxs = []\n",
    "        misclassified_data = []\n",
    "        misclassified_labels = []\n",
    "        for i in range(x_train.shape[0]):\n",
    "            #if(i in misclassified_idxs):\n",
    "            #    pass\n",
    "            #else:\n",
    "            found = run_knn(subset_data, subset_labels, np.reshape(x_train[i], (1,-1)), np.reshape(y_train[i], (1,-1)), 1)\n",
    "            if(found < 0.5):\n",
    "                misclassified_idxs.append(i)\n",
    "                misclassified_data.append(x_train[i])\n",
    "                misclassified_labels.append(y_train[i])\n",
    "        train_acc = run_knn(subset_data, subset_labels, x_train, y_train, 1)\n",
    "        test_acc = run_knn(subset_data, subset_labels, x_test, y_test, 1)\n",
    "        print(\"[Iter \", iter, \"] Subset size: \", subset_data.shape[0], \" Misclassified: \", len(misclassified_data), \" Training accuracy: \", train_acc, \" Test Accuracy: \", test_acc)\n",
    "        misclassified_data = np.array(misclassified_data)\n",
    "        misclassified_labels = np.array(misclassified_labels)\n",
    "        for label in range(10):\n",
    "            idxs = np.flatnonzero(misclassified_labels == label)\n",
    "            if(idxs.shape[0] != 0):\n",
    "                #print(idxs.shape[0], \" points of label \", label, \" misclassified\")\n",
    "                centroid_data =  np.sum(np.take(misclassified_data, idxs, axis=0), axis=0).reshape(1, misclassified_data.shape[1])/idxs.shape[0]\n",
    "                #print(\"Adding centroid of all these points to subset: \", centroid_data.shape)\n",
    "                subset_data = np.append(subset_data, centroid_data, axis=0)\n",
    "                subset_labels = np.append(subset_labels, label)\n",
    "        #print(\"Iter \", iter, \"New Subset size: \", subset_data.shape, \" \", subset_labels.shape)\n",
    "        iter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_subset_ids = initialize_cnn_subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_subset_ids = condense(cnn_subset_ids, x_train, y_train, x_test, y_test)\n",
    "plot_accuracies(sample_sizes, random_prototyping_accuracy, cnn_accuracy)\n",
    "#modified_condense(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = [1000, 4945, 10000]\n",
    "n_iterations = 5\n",
    "\n",
    "for i, m in enumerate(M):\n",
    "    for iter in range(n_iterations):\n",
    "        rand_idx = get_random_idx(m, x_train.shape[0])\n",
    "        rand_data = np.take(x_train, rand_idx, axis=0)\n",
    "        rand_labels = np.take(y_train, rand_idx, axis=0)\n",
    "    \n",
    "        random_prototyping_accuracy.append([m, run_knn(rand_data, rand_labels, x_test, y_test, 1)])\n",
    "        #random_prototyping_accuracy[i][iter] = run_knn(rand_data, rand_labels, x_test, y_test, 1)\n",
    "        #print(\"Sample size \", m, \" accuracy: \", random_prototyping_accuracy[i][iter])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
